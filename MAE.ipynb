{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3380685c-bb68-429c-8d32-8d6ce1b050c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98a369aa-9e74-4557-b83b-493ea2b72744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, q_dim, k_dim, v_dim, hidden_dim, num_head, dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W_q = nn.Linear(q_dim, hidden_dim)\n",
    "        self.W_k = nn.Linear(k_dim, hidden_dim)\n",
    "        self.W_v = nn.Linear(v_dim, hidden_dim)\n",
    "        self.W_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, query, key, value, valid_len = None, causal = False):\n",
    "        head_dim = self.hidden_dim // self.num_head\n",
    "        B, Lq, _ = query.shape\n",
    "        _, Lk, _ = key.shape\n",
    "        _, Lv, _ = value.shape\n",
    "        Q = self.W_q(query)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "        Q = Q.reshape(B, Lq, self.num_head, head_dim).permute(0,2,1,3)\n",
    "        K = K.reshape(B, Lk, self.num_head, head_dim).permute(0,2,1,3)\n",
    "        V = V.reshape(B, Lv, self.num_head, head_dim).permute(0,2,1,3)\n",
    "        scale = Q @ K.transpose(2,3) / (head_dim**0.5)\n",
    "        if valid_len != None:\n",
    "            mask = torch.arange(Lk)[None, None, None, : ] >= valid_len[:, None, None, None]\n",
    "            scale = scale.masked_fill(mask, -1e6)\n",
    "        if causal:\n",
    "            causal_mask = torch.zeros(Lq,Lk).triu(1).bool()\n",
    "            scale = scale.masked_fill(causal_mask[None, None, :,:], -1e6)\n",
    "        weight = F.softmax(scale, dim = -1) \n",
    "        weight = self.dropout(weight)\n",
    "        out = weight @ V\n",
    "        O = out.reshape(B, Lq, self.hidden_dim)\n",
    "        return self.W_o(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aa2f4b1-b50e-4b4d-beaa-1cb05f3907c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim, ff_dim, dropout):\n",
    "        super().__init()\n",
    "        self.fc1 = nn.Linear(hidden_dim, ff_dim)\n",
    "        self.fc2 = nn.Linear(ff_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        return  self.fc2(self.dropout(F.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd5a36b-4bdd-4b0a-93df-50e7dc985748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_head, ff_dim, dropout):\n",
    "        super().__init()\n",
    "        self.attention = MultiHeadAttention(hidden_dim, hidden_dim, hidden_dim, hidden_dim, num_head, dropout)\n",
    "        self.mlp = FeedForward(hidden_dim, ff_dim, dropout)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self, x):\n",
    "        att = self.attention(x, x, x)\n",
    "        x = self.norm1(x + att)\n",
    "        m = self.mlp(x)\n",
    "        x = self.norm2(x + m)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45addc60-c454-4b81-9cb2-ddee901025a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, image_size = 224, patch_size = 16, channel = 3, hidden_dim = 768):\n",
    "        super().__init__()\n",
    "        self.hidden_dim =hidden_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patchs = (image_size//patch_size)**2\n",
    "        self.patch_dim = self.patch_size**2*channel\n",
    "        self.proj = nn.Linear(self.patch_dim, hidden_dim)\n",
    "    def forward(self, X):\n",
    "        B, C, H, W = X.shape\n",
    "        X = X.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        X = X.contiguous().view(B, C, self.num_patchs, -1)\n",
    "        X = X.permute(0, 2, 1, 3).contiguous().view(B, -1, self.patch_dim)\n",
    "        return self.proj(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d124a9-8711-4bc3-95e8-64e6e856e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_mask(nn.Module):\n",
    "    def __init__(self, num_patch, hidden_dim, mask_proportion = 0.8):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim \n",
    "        self.keep_attention =int(num_patch * (1-mask_proportion))\n",
    "    def forward(self, X):\n",
    "        B, L, hidden = X.shape\n",
    "        noise = torch.rand(B, L)\n",
    "        suffle_index = torch.argsort(noise, dim=1)\n",
    "        keep_index = suffle_index[:, :self.keep_attention].unsqueeze(-1).repeat(1, 1, self.hidden_dim)\n",
    "        keep = torch.gather(X, dim=1, index = keep_index)\n",
    "        recovery_index = torch.argsort(suffle_index, dim = 1)\n",
    "        return keep, recovery_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37204490-0d4b-468e-8233-2ced8f633b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, channel, hidden_dim,  num_layer, decoder_num_layer, num_head, ff_dim, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim \n",
    "        self.patchembed = PatchEmbedding(image_size, patch_size, channel, hidden_dim)\n",
    "        self.encoder = nn.ModuleList([EncoderBlock(hidden_dim, num_head, ff_dim, dropout) for _ in range(num_layer)])\n",
    "        self.posEmbed =  nn.Parameter(torch.zeros(1, (image_size//patch_size)**2, hidden_dim))\n",
    "        self.decoder_posEmbed =  nn.Parameter(torch.zeros(1, (image_size//patch_size)**2, hidden_dim))\n",
    "        self.num_patch = (image_size//patch_size)**2\n",
    "        self.mask = random_mask(self.num_patch, hidden_dim)\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, self.hidden_dim))\n",
    "        self.decoder = nn.ModuleList([EncoderBlock(hidden_dim, num_head, ff_dim, dropout) for _ in range(decoder_num_layer)])\n",
    "        self.patch_dim = patch_size**2*channel\n",
    "        self.head = nn.Linear(hidden_dim, self.patch_dim)\n",
    "        nn.init.trunc_normal_(self.posEmbed,std = 0.02)\n",
    "        nn.init.trunc_normal_(self.decoder_posEmbed,std = 0.02)\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, C, H, W = X.shape\n",
    "        X = self.patchembed(X)\n",
    "        keep, recovery = self.mask(X)\n",
    "        pos = self.posEmbed[:, :keep.size(1), :]\n",
    "        keep = keep + pos\n",
    "        for layer in self.encoder:\n",
    "            keep = layer(keep)\n",
    "        masked_token = self.mask_token.repeat(B, self.num_patch-keep.size(1), self.hidden_dim)\n",
    "        full = torch.cat((keep, masked_token), dim = 1)\n",
    "        full = torch.gather(full, dim=1, index = recovery.unsqueeze(-1).repeat(1, 1, self.hidden_dim))\n",
    "        full = full + self.decoder_posEmbed[:, :full.size(1), :]\n",
    "        for layer in self.decoder:\n",
    "            full = layer(full)\n",
    "        return self.head(full)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1d7f2-51b0-4b84-bcc9-bd259f848e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
